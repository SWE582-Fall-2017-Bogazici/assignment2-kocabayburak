{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 253.620021909\n",
      "1 : 251.913914932\n",
      "2 : 250.219709044\n",
      "3 : 248.537321226\n",
      "4 : 246.866669041\n",
      "5 : 245.207670624\n",
      "6 : 243.560244685\n",
      "7 : 241.924310497\n",
      "8 : 240.299787898\n",
      "9 : 238.686597286\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import time\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#y = np.array([7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73])\n",
    "y = np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
    "#y = np.array([9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74])\n",
    "x = np.array([10., 8., 13., 9., 11., 14., 6., 4., 12., 7., 5.])\n",
    "N = len(x)\n",
    "\n",
    "# Design matrix\n",
    "A = np.vstack((np.ones(N), x, x**2, x**3)).T\n",
    "\n",
    "# Learning rate\n",
    "\n",
    "eta = 0.000000001\n",
    "              \n",
    "# initial parameters\n",
    "w = np.array([2., 1.,0.1, 0.001])\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Error\n",
    "    err = y-A.dot(w)\n",
    "    \n",
    "    # Total error\n",
    "    E = np.sum(err**2)/N\n",
    "    \n",
    "    # Gradient\n",
    "    dE = -2.*A.T.dot(err)/N\n",
    "        \n",
    "    if epoch%1 == 0: \n",
    "        print(epoch,':',E)\n",
    "        # print(w)    \n",
    "\n",
    "    # Perfom one descent step\n",
    "    w = w - eta*dE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradientCalc(eta, A ,w, y):\n",
    "    beta = 0.99  \n",
    "    p = 0\n",
    "    for epoch in range(1000):        \n",
    "        err = y-A.dot(w)    \n",
    "        E = np.sum(err**2)/N\n",
    "        dE = -2.*A.T.dot(err)/N\n",
    "        p = dE + beta*p\n",
    "        w = w - eta*p    \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - E :  7.91568384698  eta :  1.3310000000000003e-09\n",
      "5 - E :  7.30008589457  eta :  2.1435888100000007e-09\n",
      "10 - E :  6.42899137451  eta :  3.4522712143931024e-09\n",
      "15 - E :  5.24174733601  eta :  5.559917313492237e-09\n",
      "20 - E :  3.84476162161  eta :  8.954302432552387e-09\n",
      "25 - E :  2.4958935785  eta :  1.442099361064995e-08\n",
      "30 - E :  1.58531260219  eta :  2.322515441988786e-08\n",
      "35 - E :  1.27913323638  eta :  3.740434344477361e-08\n",
      "40 - E :  2.88254364928  eta :  1.2446295281248422e-08\n",
      "45 - E :  8.69512355436  eta :  3.889467275390132e-10\n",
      "50 - E :  9.05268840519  eta :  1.2154585235594162e-11\n",
      "55 - E :  188.144433288  eta :  3.7983078861231756e-13\n",
      "60 - E :  235.388062474  eta :  1.1869712144134924e-14\n",
      "65 - E :  237.031466707  eta :  3.7092850450421637e-16\n",
      "70 - E :  237.082997164  eta :  1.1591515765756762e-17\n",
      "75 - E :  237.084607661  eta :  3.622348676798988e-19\n",
      "80 - E :  237.084657989  eta :  1.1319839614996837e-20\n",
      "85 - E :  237.084659562  eta :  3.5374498796865117e-22\n",
      "90 - E :  237.084659611  eta :  1.1054530874020349e-23\n",
      "95 - E :  237.084659613  eta :  3.454540898131359e-25\n",
      "\n",
      "Minimum E:  1.25507501646 Optimal eta:  4.978518112499369e-08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "etaOpt = eta \n",
    "E_first = GradientCalc(eta, A ,w, y)\n",
    "eta = eta *1.1    \n",
    "E_next = GradientCalc(eta, A ,w, y)\n",
    "E_min = 0\n",
    "\n",
    "for i in range(100):\n",
    "    if E_first <= E_next:\n",
    "        eta = eta / 2\n",
    "    else:\n",
    "        eta = eta *1.1\n",
    "        if E_min > E_next: \n",
    "            etaOpt = eta\n",
    "            E_min = E_next\n",
    "        if E_min == 0:\n",
    "            etaOpt = eta\n",
    "            E_min = E_next\n",
    "    E_first = E_next\n",
    "    E_next = GradientCalc(eta, A ,w, y)\n",
    "    if i %5  == 0: \n",
    "        print(i,'- E : ',E_next, \" eta : \", eta)\n",
    "    \n",
    "print(\"\")\n",
    "print ( \"Minimum E: \", E_min ,\"Optimal eta: \", etaOpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
