{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 253.620021909\n",
      "1 : 251.913914932\n",
      "2 : 250.219709044\n",
      "3 : 248.537321226\n",
      "4 : 246.866669041\n",
      "5 : 245.207670624\n",
      "6 : 243.560244685\n",
      "7 : 241.924310497\n",
      "8 : 240.299787898\n",
      "9 : 238.686597286\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import time\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#y = np.array([7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73])\n",
    "y = np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
    "#y = np.array([9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74])\n",
    "x = np.array([10., 8., 13., 9., 11., 14., 6., 4., 12., 7., 5.])\n",
    "N = len(x)\n",
    "\n",
    "# Design matrix\n",
    "A = np.vstack((np.ones(N), x, x**2, x**3)).T\n",
    "\n",
    "# Learning rate\n",
    "\n",
    "eta = 0.000000001\n",
    "              \n",
    "# initial parameters\n",
    "w = np.array([2., 1.,0.1, 0.001])\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Error\n",
    "    err = y-A.dot(w)\n",
    "    \n",
    "    # Total error\n",
    "    E = np.sum(err**2)/N\n",
    "    \n",
    "    # Gradient\n",
    "    dE = -2.*A.T.dot(err)/N\n",
    "        \n",
    "    if epoch%1 == 0: \n",
    "        print(epoch,':',E)\n",
    "        # print(w)    \n",
    "\n",
    "    # Perfom one descent step\n",
    "    w = w - eta*dE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradientCalc(eta, A ,w, y):\n",
    "    beta = 0.99  \n",
    "    p = 0\n",
    "    for epoch in range(1000):        \n",
    "        err = y-A.dot(w)    \n",
    "        E = np.sum(err**2)/N\n",
    "        dE = -2.*A.T.dot(err)/N\n",
    "        p = dE + beta*p\n",
    "        w = w - eta*p    \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - E :  8.01120492875  eta :  1.2100000000000002e-09\n",
      "5 - E :  7.44680099242  eta :  1.9487171000000006e-09\n",
      "10 - E :  6.62076128045  eta :  3.138428376721002e-09\n",
      "15 - E :  5.5007886775  eta :  5.054470284992942e-09\n",
      "20 - E :  4.13900961777  eta :  8.140274938683987e-09\n",
      "25 - E :  2.74143884626  eta :  1.3109994191499954e-08\n",
      "30 - E :  1.71842620055  eta :  2.11137767453526e-08\n",
      "35 - E :  1.29294399752  eta :  3.4003948586157825e-08\n",
      "40 - E :  1.49869823728  eta :  2.4892590562496844e-08\n",
      "45 - E :  8.36209910082  eta :  7.778934550780264e-10\n",
      "50 - E :  9.023562255  eta :  2.4309170471188324e-11\n",
      "55 - E :  148.915815584  eta :  7.596615772246351e-13\n",
      "60 - E :  233.702930317  eta :  2.3739424288269848e-14\n",
      "65 - E :  236.978285065  eta :  7.418570090084327e-16\n",
      "70 - E :  237.081334726  eta :  2.3183031531513523e-17\n",
      "75 - E :  237.084555709  eta :  7.244697353597976e-19\n",
      "80 - E :  237.084656366  eta :  2.2639679229993675e-20\n",
      "85 - E :  237.084659511  eta :  7.074899759373023e-22\n",
      "90 - E :  237.08465961  eta :  2.2109061748040698e-23\n",
      "95 - E :  237.084659613  eta :  6.909081796262718e-25\n",
      "\n",
      "Minimum E:  1.25507501646 Optimal eta:  4.978518112499369e-08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "etaOpt = eta \n",
    "E_first = GradientCalc(eta, A ,w, y)\n",
    "eta = eta *1.1    \n",
    "E_next = GradientCalc(eta, A ,w, y)\n",
    "E_min = 0\n",
    "\n",
    "for i in range(100):\n",
    "    if E_first <= E_next:\n",
    "        eta = eta / 2\n",
    "    else:\n",
    "        eta = eta *1.1\n",
    "        if E_min > E_next: \n",
    "            etaOpt = eta\n",
    "            E_min = E_next\n",
    "        if E_min == 0:\n",
    "            etaOpt = eta\n",
    "            E_min = E_next\n",
    "    E_first = E_next\n",
    "    E_next = GradientCalc(eta, A ,w, y)\n",
    "    if i %5  == 0: \n",
    "        print(i,'- E : ',E_next, \" eta : \", eta)\n",
    "    \n",
    "print(\"\")\n",
    "print ( \"Minimum E: \", E_min ,\"Optimal eta: \", etaOpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
